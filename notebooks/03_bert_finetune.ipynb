{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f272a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s38976581_gmail_com/micromamba/envs/fin_sentiment/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "import ml_collections\n",
    "import datasets\n",
    "import torch\n",
    "import transformers\n",
    "import evaluate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from accelerate import Accelerator, DistributedType\n",
    "from datasets import Dataset, DatasetDict\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "from utils import clean_text, preprocess_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67982814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the model hyperparameters\n",
    "datetime_now = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "def model_config():\n",
    "    cfg_dictionary = {\n",
    "        \"data_path\": \"../data/data.csv\",\n",
    "        \"test_split_size\": 0.2,\n",
    "        \"validation_split_size\":0.2,\n",
    "                \n",
    "        \"model_path\": \"/model/roberta_base_model.h5\",\n",
    "\n",
    "        \"train_batch_size\": 32,\n",
    "        \"eval_batch_size\": 32,\n",
    "\n",
    "        \"epochs\": 5,\n",
    "        \"adam_epsilon\": 1e-8,\n",
    "        \"lr\": 3e-5,\n",
    "        \"num_warmup_steps\": 10,\n",
    "\n",
    "        \"max_length\": 128,\n",
    "        \"random_seed\": 42,\n",
    "        \"num_labels\": 3,\n",
    "        \"model_checkpoint\":\"FacebookAI/roberta-base\",\n",
    "\n",
    "    }\n",
    "    cfg = ml_collections.FrozenConfigDict(cfg_dictionary)\n",
    "\n",
    "    return cfg\n",
    "cfg = model_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea963a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataframe):\n",
    "    train_df, test_df = train_test_split(\n",
    "        dataframe,\n",
    "        test_size=cfg.test_split_size,\n",
    "        random_state=cfg.random_seed,\n",
    "        stratify=dataframe.labels.values,\n",
    "    )\n",
    "    train_df, val_df = train_test_split(\n",
    "        train_df,\n",
    "        test_size=cfg.validation_split_size,\n",
    "        random_state=cfg.random_seed,\n",
    "        stratify=train_df.labels.values,\n",
    "    )\n",
    "\n",
    "    dataset = {\n",
    "        \"train\": Dataset.from_pandas(train_df),\n",
    "        \"validation\": Dataset.from_pandas(val_df),\n",
    "        \"test\": Dataset.from_pandas(test_df),\n",
    "    }\n",
    "\n",
    "    dataset = DatasetDict(dataset)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04b75963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_csv(csv_file: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    labelencoder = LabelEncoder()\n",
    "    df[\"labels\"] = labelencoder.fit_transform(df[\"Sentiment\"])\n",
    "    df.drop_duplicates(subset=['Sentence'],keep='first',inplace=True)\n",
    "\n",
    "    cleaned_df = clean_text(df, \"Sentence\")\n",
    "    df.rename(columns={\"Sentiment\": \"sentiment\"}, inplace=True)\n",
    "    df.rename(columns={\"Sentence\": \"sentence\"}, inplace=True)\n",
    "\n",
    "    return cleaned_df\n",
    "\n",
    "\n",
    "def tokenize_dataset():\n",
    "    dataset = create_dataset(preprocess_csv(cfg.data_path))\n",
    "    tokenizer = AutoTokenizer.from_pretrained(cfg.model_checkpoint,use_fast=True)\n",
    "\n",
    "    def tokenize_function(sample):\n",
    "        outputs = tokenizer(\n",
    "            sample[\"sentence\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=cfg.max_length,\n",
    "        )\n",
    "        return outputs\n",
    "\n",
    "    tokenized_datasets = dataset.map(\n",
    "        tokenize_function, batched=True, remove_columns=[\"sentence\",\"sentiment\",\"__index_level_0__\"]\n",
    "    )\n",
    "    # Rename 'label' to 'labels' as expected by HuggingFace models\n",
    "    tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "    return tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c22ea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(tokenized_datasets):\n",
    "    train_dataloader = DataLoader(\n",
    "        tokenized_datasets[\"train\"], shuffle=True, batch_size=cfg.train_batch_size\n",
    "    )\n",
    "    eval_dataloader = DataLoader(\n",
    "        tokenized_datasets[\"validation\"], shuffle=False, batch_size=cfg.eval_batch_size\n",
    "    )\n",
    "    return train_dataloader, eval_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdafff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function():\n",
    "    accelerator = Accelerator()\n",
    "\n",
    "    set_seed(cfg.random_seed)\n",
    "    tokenized_datasets = tokenize_dataset()\n",
    "    accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "    # if accelerator.is_main_process:\n",
    "    #     datasets.utils.logging.set_verbosity_warning()\n",
    "    #     transformers.utils.logging.set_verbosity_info()\n",
    "    # else:\n",
    "    #     datasets.utils.logging.set_verbosity_error()\n",
    "    #     transformers.utils.logging.set_verbosity_error()\n",
    "\n",
    "    train_dataloader, eval_dataloader = create_dataloaders(tokenized_datasets)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        cfg.model_checkpoint, num_labels=cfg.num_labels\n",
    "    )\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        params=model.parameters(), eps=cfg.adam_epsilon, lr=cfg.lr\n",
    "    )\n",
    "    model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "        model, optimizer, train_dataloader, eval_dataloader\n",
    "    )\n",
    "    lr_scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=cfg.num_warmup_steps,\n",
    "        num_training_steps=len(train_dataloader) * cfg.epochs,\n",
    "    )\n",
    "    progress_bar = tqdm(\n",
    "        range(cfg.epochs * len(train_dataloader)),\n",
    "        # disable=not accelerator.is_main_process,\n",
    "    )\n",
    "\n",
    "    best_accuracy = 0\n",
    "    checkpoint_dir = \"../results/checkpoints\"\n",
    "\n",
    "    # Model Training\n",
    "    for epoch in range(cfg.epochs):\n",
    "        model.train()\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            # print(batch[\"labels\"])\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            # print(loss.item())\n",
    "            accelerator.backward(loss)\n",
    "            \n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        model.eval()\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "\n",
    "        for step, batch in enumerate(eval_dataloader):\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch)\n",
    "            predictions = outputs.logits.argmax(dim=-1)\n",
    "\n",
    "            # gather predictions and labels from the multiple TPUs/GPUs (if applicable)\n",
    "            all_predictions.append(accelerator.gather(predictions))\n",
    "            all_labels.append(accelerator.gather(batch[\"labels\"]))\n",
    "\n",
    "        # Concatenate all predictions and labels.\n",
    "        all_predictions = torch.cat(all_predictions)[\n",
    "            : len(tokenized_datasets[\"validation\"])\n",
    "        ]\n",
    "        all_labels = torch.cat(all_labels)[: len(tokenized_datasets[\"validation\"])]\n",
    "\n",
    "        eval_accuracy = accuracy.compute(\n",
    "            predictions=all_predictions, references=all_labels\n",
    "        )\n",
    "\n",
    "        # Use accelerator.print to print only on the main process.\n",
    "        accelerator.print(f\"epoch {epoch}:\", eval_accuracy)\n",
    "\n",
    "        # Save checkpoint if this is the best model so far\n",
    "        if eval_accuracy[\"accuracy\"] > best_accuracy:\n",
    "            best_accuracy = eval_accuracy[\"accuracy\"]\n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f\"{checkpoint_dir}/roberta-base-best\",\n",
    "                save_function=accelerator.save\n",
    "            )\n",
    "            # Also save the tokenizer for easy loading later\n",
    "            tokenizer = AutoTokenizer.from_pretrained(cfg.model_checkpoint)\n",
    "            tokenizer.save_pretrained(f\"{checkpoint_dir}/roberta-best\")\n",
    "            accelerator.print(f\"Saved new best model with accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80ec58ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3405/3405 [00:00<00:00, 10777.10 examples/s]\n",
      "Map: 100%|██████████| 852/852 [00:00<00:00, 11429.50 examples/s]\n",
      "Map: 100%|██████████| 1065/1065 [00:00<00:00, 3285.29 examples/s]\n",
      "Loading weights: 100%|██████████| 197/197 [00:00<00:00, 572.34it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n",
      "RobertaForSequenceClassification LOAD REPORT from: FacebookAI/roberta-base\n",
      "Key                             | Status     | \n",
      "--------------------------------+------------+-\n",
      "lm_head.dense.weight            | UNEXPECTED | \n",
      "lm_head.layer_norm.bias         | UNEXPECTED | \n",
      "roberta.embeddings.position_ids | UNEXPECTED | \n",
      "lm_head.dense.bias              | UNEXPECTED | \n",
      "lm_head.layer_norm.weight       | UNEXPECTED | \n",
      "lm_head.bias                    | UNEXPECTED | \n",
      "classifier.dense.weight         | MISSING    | \n",
      "classifier.dense.bias           | MISSING    | \n",
      "classifier.out_proj.weight      | MISSING    | \n",
      "classifier.out_proj.bias        | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n",
      " 20%|██        | 107/535 [00:31<02:08,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'accuracy': 0.8497652582159625}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n",
      " 20%|██        | 108/535 [00:35<10:11,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new best model with accuracy: 0.8498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 215/535 [01:09<05:28,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: {'accuracy': 0.8438967136150235}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 321/535 [01:40<01:02,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: {'accuracy': 0.8720657276995305}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing model shards: 100%|██████████| 1/1 [00:02<00:00,  2.98s/it]\n",
      " 60%|██████    | 322/535 [01:46<07:17,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new best model with accuracy: 0.8721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 428/535 [02:18<00:31,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: {'accuracy': 0.8732394366197183}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing model shards: 100%|██████████| 1/1 [00:02<00:00,  2.84s/it]\n",
      " 80%|████████  | 429/535 [02:24<03:35,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new best model with accuracy: 0.8732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 535/535 [02:55<00:00,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: {'accuracy': 0.8744131455399061}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing model shards: 100%|██████████| 1/1 [00:02<00:00,  2.99s/it]\n",
      "100%|██████████| 535/535 [03:01<00:00,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new best model with accuracy: 0.8744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## TRAINING\n",
    "training_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb0c1d0",
   "metadata": {},
   "source": [
    "GPU memory usage:  4492MiB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c42d354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  59%|█████▊    | 2000/3405 [00:00<00:00, 10816.42 examples/s]"
     ]
    }
   ],
   "source": [
    "## Save results from test set for evaluation later\n",
    "\n",
    "def evaluate_and_save_test_results(output_path=\"../results/predictions/roberta_base_predictions.pkl\"):\n",
    "    \"\"\"Evaluate on test set and save results for later analysis.\"\"\"\n",
    "    accelerator = Accelerator()\n",
    "    set_seed(cfg.random_seed)\n",
    "    \n",
    "    # Recreate tokenized datasets\n",
    "    tokenized_datasets = tokenize_dataset()\n",
    "    \n",
    "    # Load the fine-tuned model (not the pretrained checkpoint)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"../results/checkpoints/roberta-base-best\", num_labels=cfg.num_labels\n",
    "    )\n",
    "    \n",
    "    # Create test dataloader\n",
    "    test_dataloader = DataLoader(\n",
    "        tokenized_datasets[\"test\"], shuffle=False, batch_size=cfg.eval_batch_size\n",
    "    )\n",
    "    \n",
    "    model, test_dataloader = accelerator.prepare(model, test_dataloader)\n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    for batch in tqdm(test_dataloader, desc=\"Evaluating test set\"):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        \n",
    "        logits = outputs.logits\n",
    "        probabilities = torch.softmax(logits, dim=-1)\n",
    "        predictions = logits.argmax(dim=-1)\n",
    "        \n",
    "        all_predictions.append(accelerator.gather(predictions).cpu().numpy())\n",
    "        all_labels.append(accelerator.gather(batch[\"labels\"]).cpu().numpy())\n",
    "        all_probabilities.append(accelerator.gather(probabilities).cpu().numpy())\n",
    "    \n",
    "    # Concatenate and trim to actual test set size\n",
    "    test_size = len(tokenized_datasets[\"test\"])\n",
    "    all_predictions = np.concatenate(all_predictions)[:test_size]\n",
    "    all_labels = np.concatenate(all_labels)[:test_size]\n",
    "    all_probabilities = np.concatenate(all_probabilities)[:test_size]\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = (all_predictions == all_labels).mean()\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Save results using pickle (consistent with ml_baselines notebook)\n",
    "    import pickle\n",
    "    import os\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    results = {\n",
    "        \"RoBERTa-base\": all_predictions,\n",
    "        \"y_true\": all_labels,\n",
    "        \"probabilities\": all_probabilities,\n",
    "    }\n",
    "    \n",
    "    with open(output_path, 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "    \n",
    "    print(f\"Results saved to {output_path}\")\n",
    "    \n",
    "    return all_predictions, all_labels, all_probabilities\n",
    "\n",
    "# Run evaluation and save\n",
    "predictions, labels, probabilities = evaluate_and_save_test_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719bede7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fin_sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
